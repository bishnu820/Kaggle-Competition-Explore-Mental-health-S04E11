{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84895,"databundleVersionId":10008389,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-12-01T05:23:58.113858Z","iopub.execute_input":"2024-12-01T05:23:58.114405Z","iopub.status.idle":"2024-12-01T05:23:58.126809Z","shell.execute_reply.started":"2024-12-01T05:23:58.114372Z","shell.execute_reply":"2024-12-01T05:23:58.125428Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s4e11/sample_submission.csv\n/kaggle/input/playground-series-s4e11/train.csv\n/kaggle/input/playground-series-s4e11/test.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-12-01T05:23:58.133717Z","iopub.execute_input":"2024-12-01T05:23:58.134174Z","iopub.status.idle":"2024-12-01T05:23:58.139923Z","shell.execute_reply.started":"2024-12-01T05:23:58.134138Z","shell.execute_reply":"2024-12-01T05:23:58.138718Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"pd.set_option(\"display.max_columns\",None)\npd.set_option(\"display.max_rows\",None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:23:58.144365Z","iopub.execute_input":"2024-12-01T05:23:58.145001Z","iopub.status.idle":"2024-12-01T05:23:58.161136Z","shell.execute_reply.started":"2024-12-01T05:23:58.144964Z","shell.execute_reply":"2024-12-01T05:23:58.159694Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_df=pd.read_csv(\"/kaggle/input/playground-series-s4e11/train.csv\")\ntest_df=pd.read_csv(\"/kaggle/input/playground-series-s4e11/test.csv\")\nsubmission_df=pd.read_csv(\"/kaggle/input/playground-series-s4e11/sample_submission.csv\")\ndf,test=train_test_split(train_df,test_size=0.2,random_state=87)","metadata":{"execution":{"iopub.status.busy":"2024-12-01T09:14:46.576575Z","iopub.execute_input":"2024-12-01T09:14:46.577535Z","iopub.status.idle":"2024-12-01T09:14:47.248732Z","shell.execute_reply.started":"2024-12-01T09:14:46.577487Z","shell.execute_reply":"2024-12-01T09:14:47.247338Z"},"trusted":true},"outputs":[],"execution_count":65},{"cell_type":"code","source":"invalid_professions = [\n    \"Unveil\", \"BE\", \"Visakhapatnam\", \"Moderate\", \"BCA\", \"LLM\", \"PhD\", \"B.Com\",\n    \"Profession\", \"B.Ed\", \"Yuvraj\", \"Yogesh\", \"Nagpur\", \"Pranav\", \"Patna\", \"BBA\", \"M.Ed\"]\ninvalid_sleep_duration = [\n    'Indore',\n    'Unhealthy',\n    'Pune',\n    'Sleep_Duration'\n]\ninvalid_dietry_habits=['BSc', '3', '2', 'Indoor', 'M.Tech', 'Pratham', 'Class 12', 'Male', 'Yes', '1.0', 'Mihir', 'Electrician']\ninvalid_degrees = [\n    'UX/UI Designer', 'Degree', 'Data Scientist', 'LL.Com', 'S.Arch',\n    '5.56', 'Brithika','29', 'Kalyan', 'Bhopal', 'Plumber', 'Pihu',\n    'Brit', 'M', 'Mihir', 'Vivaan', 'CGPA', 'B', '8.56', 'BB',\n    'Lata', '5.88', 'B.03',\n    'Jhanvi', '20', 'Nalini', 'Ritik', '7.06', 'Aarav', 'Esha', 'Entrepreneur','Badhya',\n    'Unite', 'Navya', '24']","metadata":{"execution":{"iopub.status.busy":"2024-12-01T05:23:59.262075Z","iopub.execute_input":"2024-12-01T05:23:59.262411Z","iopub.status.idle":"2024-12-01T05:23:59.269671Z","shell.execute_reply.started":"2024-12-01T05:23:59.262378Z","shell.execute_reply":"2024-12-01T05:23:59.268499Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import numpy as np\n\n# Sleep duration categories\nshort_sleep = [\n    'Less than 5 hours', '3-4 hours', '2-3 hours', '4-5 hours',\n    '5-6 hours', '4-6 hours', '1-6 hours', '3-6 hours', '1-2 hours',\n    '1-3 hours', 'than 5 hours'\n]\n\nnormal_sleep = [\n    '6-7 hours', '7-8 hours', '6-8 hours', '8 hours', '10-6 hours',\n    '9-6 hours', '45', '9-5 hours', '9-5', '35-36 hours', '8 hours',\n    '40-45 hours', '45-48 hours'\n]\n\nlong_sleep = [\n    '55-66 hours', 'More than 8 hours', '8-9 hours', '9-11 hours', '10-11 hours'\n]\n\n# Function to categorize sleep duration\ndef sleep_cat(value):\n    if value in short_sleep:\n        return \"Short sleep duration\"\n    elif value in normal_sleep:\n        return \"Normal sleep duration\"\n    elif value in long_sleep:\n        return \"Long sleep duration\"\n    else:\n        return np.nan\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:23:59.271858Z","iopub.execute_input":"2024-12-01T05:23:59.272210Z","iopub.status.idle":"2024-12-01T05:23:59.283208Z","shell.execute_reply.started":"2024-12-01T05:23:59.272167Z","shell.execute_reply":"2024-12-01T05:23:59.282047Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Defining degree categories\nno_education = [\"0\"]\n\nhigh_school = [\n    'Class 11', 'Class 12'\n]\n\nbachelor = [\n    'BCA', 'BE', 'B.Pharm', 'BHM', 'B.Ed', 'B.Com', 'B.Arch', 'BSc', 'B.Tech', 'BBA',\n    'BA', 'LLB', 'B.Sc', 'BPharm', 'BArch', 'B BA',\"BH\",\"B.Student\",'LL B.Ed',\"BArch\",'B BA',\"MBBS\"\n]\n\nmaster_and_higher = [\n    'M.Pharm','MBA', 'MCA', 'PhD', 'MD', 'ME', 'M.Ed', 'MA', 'M.Tech', 'MSc', 'LLM',\n    'MHM', 'M.Com', 'MEd', 'L.Ed', 'LLEd', 'MPharm', 'M.Arch', 'LLCom', 'LLBA','Advait', 'Doctor', 'M. Business Analyst', \"MPA\"]\n\n\n# Function to map degree to categories\ndef categorize_degree(degree):\n    if degree in no_education:\n        return \"No Education\"\n    elif degree in high_school:\n        return \"High School\"\n    elif degree in bachelor:\n        return \"Bachelor\"\n    elif degree in master_and_higher:\n        return \"Master and Higher\"\n    else:\n        return \"Unknown\"\n\n# Applying the function\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:23:59.284693Z","iopub.execute_input":"2024-12-01T05:23:59.285149Z","iopub.status.idle":"2024-12-01T05:23:59.302032Z","shell.execute_reply.started":"2024-12-01T05:23:59.285092Z","shell.execute_reply":"2024-12-01T05:23:59.300850Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":" # Function to map dietary habits\ndef map_dietary_habits(value):\n    if value in [ \"No Healthy\",\"Unhealthy\",\"No\"]:\n        return \"Unhealthy\"\n    elif value in [\"More Healthy\",\"Healthy\"]:\n        return \"Healthy\"\n    elif value in [ \"Less Healthy\",\"Moderate\"]:\n        return \"Moderate\"\n    else:\n        return np.nan\n\n# Apply the function to the 'Dietary Habits' column\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:23:59.303456Z","iopub.execute_input":"2024-12-01T05:23:59.303829Z","iopub.status.idle":"2024-12-01T05:23:59.316523Z","shell.execute_reply.started":"2024-12-01T05:23:59.303783Z","shell.execute_reply":"2024-12-01T05:23:59.315162Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Blank mapping dictionary for manual entries\nhours_mapping = {\n    '7-8 hours': 7.5,\n    '5-6 hours': 5.5,\n    'Less than 5 hours': 2.5,\n    'More than 8 hours': 10,\n    '3-4 hours': 3.5,\n    '4-6 hours': 5,\n    '2-3 hours': 3.5,\n    '10-6 hours': 8,\n    '1-6 hours': 3.5,\n    '55-66 hours':57.5/7,\n    np.nan: np.nan,\n    '6-8 hours': 7,\n    '4-5 hours': 4.5,\n    '9-6 hours': 7.5,\n    '45': 45/7,\n    '6-7 hours': 6.5,\n    '9-5 hours': 7,\n    '10-11 hours': 10.5,\n    'No': 0,\n    '9-5': 7,\n    '35-36 hours': 35.5/7,\n    '8-9 hours': 8.5,\n    '8 hours': 8,\n    '40-45 hours': 42.5/7,\n    '3-6 hours': 4.5,\n    '9-11 hours': 10,\n    '45-48 hours': 46.5/7,\n    '1-2 hours': 1.5,\n    'than 5 hours': 2.5\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:23:59.318426Z","iopub.execute_input":"2024-12-01T05:23:59.318906Z","iopub.status.idle":"2024-12-01T05:23:59.337518Z","shell.execute_reply.started":"2024-12-01T05:23:59.318856Z","shell.execute_reply":"2024-12-01T05:23:59.336176Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndef create_features(df):\n    \"\"\"\n    Create new features based on the existing columns of the dataset.\n\n    Parameters:\n        df (pd.DataFrame): Input dataframe with raw data.\n\n    Returns:\n        pd.DataFrame: Dataframe with new features added.\n    \"\"\"\n    # Avoid modifying the original dataframe\n    \n    df = df.copy()\n\n    # Pressure-to-Satisfaction Ratio\n    df['Pressure_to_Satisfaction_Ratio'] = (\n        (df['Academic Pressure_imputed'] + df['Work Pressure_imputed']) /\n        (df['Study Satisfaction_imputed'] + df['Job Satisfaction_imputed'] + 1e-8)  # To avoid division by zero\n    )\n\n    # Pressure Impact on CGPA\n    df['Pressure_Impact_on_CGPA'] = (\n        df['CGPA_imputed'] / (df['Academic Pressure_imputed'] + df['Work Pressure_imputed'] + 1e-8)\n    )\n\n    # Work-Life Balance\n    df['Work_Life_Balance'] = (\n        (df['Job Satisfaction_imputed'] + df['sleep_duration_hours']) /\n        (df['Work/Study Hours'] + 1e-8)\n    )\n\n    # Stress Level (Composite)\n    df['Stress_Level'] = (\n        df['Academic Pressure_imputed'] + df['Work Pressure_imputed'] + df['Financial Stress']\n    )\n\n    # Age Group\n    df['Age_Group'] = pd.cut(\n        df['Age'], bins=[0, 25, 40, 60, 100],\n        labels=['Youth', 'Young Adults', 'Middle-aged', 'Senior']\n    )\n\n    # Sleep-to-Work Ratio\n    df['Sleep_to_Work_Ratio'] = (\n        df['sleep_duration_hours'] / (df['Work/Study Hours'] + 1e-8)\n    )\n\n    # CGPA Efficiency\n    df['CGPA_Efficiency'] = (\n        df['CGPA_imputed'] / (df['Work/Study Hours'] + 1e-8)\n    )\n\n    # Dietary Health Score (Mapping)\n    dietary_mapping = {\n        'Healthy': 3,\n        'Moderate': 2,\n        'Unhealthy': 1\n    }\n    df['Dietary_Health_Score'] = df['Dietary Habits'].map(dietary_mapping)\n\n    # Mental Health Risk Score\n    df['Mental_Health_Risk_Score'] = (\n        df['Family History of Mental Illness'].map({'Yes': 1, 'No': 0}) +\n        df['Have you ever had suicidal thoughts ?'].map({'Yes': 1, 'No': 0}) +\n        df['Financial Stress']\n    )\n\n    # Binary Encoding for Categorical Variables\n    binary_mappings = {\n        'Have you ever had suicidal thoughts ?': {'Yes': 1, 'No': 0},\n        'Family History of Mental Illness': {'Yes': 1, 'No': 0}\n    }\n    for col, mapping in binary_mappings.items():\n        df[f'{col}_Binary'] = df[col].map(mapping)\n\n    # Overall Satisfaction\n    df['Overall_Satisfaction'] = (\n        df['Study Satisfaction_imputed'] + df['Job Satisfaction_imputed']\n    ) / 2\n\n    # Overall Pressure\n    df['Overall_Pressure'] = (\n        df['Academic Pressure_imputed'] + df['Work Pressure_imputed'] + df['Financial Stress']\n    )\n    # Return the modified dataframe\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:23:59.339484Z","iopub.execute_input":"2024-12-01T05:23:59.339938Z","iopub.status.idle":"2024-12-01T05:23:59.352889Z","shell.execute_reply.started":"2024-12-01T05:23:59.339904Z","shell.execute_reply":"2024-12-01T05:23:59.351655Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def wrangle(df):\n    columns_to_drop=[\"id\"] \n    df.drop(columns=columns_to_drop,inplace=True)\n    df[\"Degree\"]=df[\"Degree\"].apply(lambda x: np.nan if x in invalid_degrees else x)\n    df[\"Sleep Duration\"]=df[\"Sleep Duration\"].apply(lambda x: np.nan if x in invalid_sleep_duration else x)\n    df[\"Dietary Habits\"]=df[\"Dietary Habits\"].apply(lambda x: np.nan if x in invalid_dietry_habits else x)\n    df[\"Profession\"]=df[\"Profession\"].apply(lambda x: np.nan if x in invalid_professions else x)\n    df[\"sleep_duration_cat\"] = df[\"Sleep Duration\"].apply(sleep_cat)\n    df[\"Degree Category\"] = df[\"Degree\"].apply(categorize_degree)\n    df[\"Dietary Habits\"] = df[\"Dietary Habits\"].apply(map_dietary_habits)\n    df[\"Profession_imputed\"]=df.apply(lambda row: \"Student\" if  row[\"Working Professional or Student\"]==\"Student\" else row[\"Profession\"],axis=1)\n    df[\"Academic Pressure_imputed\"]=df.apply(lambda row: 0 if  row[\"Working Professional or Student\"]==\"Working Professional\" else row[\"Academic Pressure\"],axis=1)\n    df[\"Work Pressure_imputed\"]=df.apply(lambda row: 0 if  row[\"Working Professional or Student\"]==\"Student\" else row[\"Work Pressure\"],axis=1)\n    df[\"CGPA_imputed\"]=df.apply(lambda row: 0 if  row[\"Working Professional or Student\"]==\"Working Professional\" else row[\"CGPA\"],axis=1)\n    df[\"Study Satisfaction_imputed\"]=df.apply(lambda row: 0 if  row[\"Working Professional or Student\"]==\"Working Professional\" else row[\"Study Satisfaction\"],axis=1)\n    #Job Satisfaction\n    df[\"Job Satisfaction_imputed\"]=df.apply(lambda row: 0 if  row[\"Working Professional or Student\"]==\"Student\" else row[\"Job Satisfaction\"],axis=1)\n    df[\"sleep_duration_hours\"] = df[\"Sleep Duration\"].map(hours_mapping)\n    if \"Depression\" in df.columns:\n        X = df.drop(columns=\"Depression\")\n        y = df[\"Depression\"]\n        # Handle categorical columns\n        X_cat = X.select_dtypes(exclude=np.number).fillna(X.select_dtypes(exclude=np.number).mode().iloc[0])\n        # Handle numeric columns\n        X_num = X.select_dtypes(include=np.number).fillna(X.select_dtypes(include=np.number).mean())\n        df = pd.concat([X_cat, X_num,y], axis=1)\n    else:\n        df_cat = df.select_dtypes(exclude=np.number).fillna(df.select_dtypes(exclude=np.number).mode().iloc[0])\n        # Handle numeric columns\n        df_num = df.select_dtypes(include=np.number).fillna(df.select_dtypes(include=np.number).mean())\n        df = pd.concat([df_cat, df_num], axis=1)\n    df=create_features(df)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-12-01T09:14:56.872389Z","iopub.execute_input":"2024-12-01T09:14:56.872899Z","iopub.status.idle":"2024-12-01T09:14:56.887228Z","shell.execute_reply.started":"2024-12-01T09:14:56.872861Z","shell.execute_reply":"2024-12-01T09:14:56.885498Z"},"trusted":true},"outputs":[],"execution_count":66},{"cell_type":"code","source":"df=wrangle(df)\ntest=wrangle(test)","metadata":{"execution":{"iopub.status.busy":"2024-12-01T05:23:59.374161Z","iopub.execute_input":"2024-12-01T05:23:59.374546Z","iopub.status.idle":"2024-12-01T05:24:07.112687Z","shell.execute_reply.started":"2024-12-01T05:23:59.374496Z","shell.execute_reply":"2024-12-01T05:24:07.111304Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"test_submit=wrangle(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:15:00.285446Z","iopub.execute_input":"2024-12-01T09:15:00.285874Z","iopub.status.idle":"2024-12-01T09:15:05.293139Z","shell.execute_reply.started":"2024-12-01T09:15:00.285838Z","shell.execute_reply":"2024-12-01T09:15:05.292038Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-12-01T05:24:07.114181Z","iopub.execute_input":"2024-12-01T05:24:07.114494Z","iopub.status.idle":"2024-12-01T05:24:07.157226Z","shell.execute_reply.started":"2024-12-01T05:24:07.114463Z","shell.execute_reply":"2024-12-01T05:24:07.156063Z"},"trusted":true},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"            Name  Gender           City Working Professional or Student  \\\n127399     Gauri  Female       Varanasi                         Student   \n23578       Shiv    Male           Agra            Working Professional   \n127553     Manvi  Female  Visakhapatnam                         Student   \n85588     Pranav    Male       Varanasi            Working Professional   \n44808   Aaradhya  Female         Indore            Working Professional   \n\n              Profession     Sleep Duration Dietary Habits   Degree  \\\n127399           Teacher          7-8 hours        Healthy      BCA   \n23578   Research Analyst          5-6 hours       Moderate  M.Pharm   \n127553           Teacher          5-6 hours      Unhealthy      MBA   \n85588              Pilot  Less than 5 hours      Unhealthy       BE   \n44808         Pharmacist          7-8 hours        Healthy  B.Pharm   \n\n       Have you ever had suicidal thoughts ? Family History of Mental Illness  \\\n127399                                    No                               No   \n23578                                    Yes                               No   \n127553                                   Yes                              Yes   \n85588                                     No                               No   \n44808                                     No                              Yes   \n\n           sleep_duration_cat    Degree Category Profession_imputed   Age  \\\n127399  Normal sleep duration           Bachelor            Student  28.0   \n23578    Short sleep duration  Master and Higher   Research Analyst  47.0   \n127553   Short sleep duration  Master and Higher            Student  25.0   \n85588    Short sleep duration           Bachelor              Pilot  59.0   \n44808   Normal sleep duration           Bachelor         Pharmacist  45.0   \n\n        Academic Pressure  Work Pressure      CGPA  Study Satisfaction  \\\n127399           4.000000       2.999668  6.530000            2.000000   \n23578            3.145141       3.000000  7.662263            2.943501   \n127553           1.000000       2.999668  7.090000            5.000000   \n85588            3.145141       3.000000  7.662263            2.943501   \n44808            3.145141       3.000000  7.662263            2.943501   \n\n        Job Satisfaction  Work/Study Hours  Financial Stress  \\\n127399          2.973074               0.0               3.0   \n23578           4.000000               7.0               5.0   \n127553          2.973074              12.0               4.0   \n85588           5.000000               0.0               4.0   \n44808           4.000000               8.0               1.0   \n\n        Academic Pressure_imputed  Work Pressure_imputed  CGPA_imputed  \\\n127399                        4.0                    0.0          6.53   \n23578                         0.0                    3.0          0.00   \n127553                        1.0                    0.0          7.09   \n85588                         0.0                    3.0          0.00   \n44808                         0.0                    3.0          0.00   \n\n        Study Satisfaction_imputed  Job Satisfaction_imputed  \\\n127399                         2.0                       0.0   \n23578                          0.0                       4.0   \n127553                         5.0                       0.0   \n85588                          0.0                       5.0   \n44808                          0.0                       4.0   \n\n        sleep_duration_hours  Depression  Pressure_to_Satisfaction_Ratio  \\\n127399                   7.5           0                            2.00   \n23578                    5.5           0                            0.75   \n127553                   5.5           1                            0.20   \n85588                    2.5           0                            0.60   \n44808                    7.5           0                            0.75   \n\n        Pressure_Impact_on_CGPA  Work_Life_Balance  Stress_Level  \\\n127399                   1.6325       7.500000e+08           7.0   \n23578                    0.0000       1.357143e+00           8.0   \n127553                   7.0900       4.583333e-01           5.0   \n85588                    0.0000       7.500000e+08           7.0   \n44808                    0.0000       1.437500e+00           4.0   \n\n           Age_Group  Sleep_to_Work_Ratio  CGPA_Efficiency  \\\n127399  Young Adults         7.500000e+08     6.530000e+08   \n23578    Middle-aged         7.857143e-01     0.000000e+00   \n127553         Youth         4.583333e-01     5.908333e-01   \n85588    Middle-aged         2.500000e+08     0.000000e+00   \n44808    Middle-aged         9.375000e-01     0.000000e+00   \n\n        Dietary_Health_Score  Mental_Health_Risk_Score  \\\n127399                     3                       3.0   \n23578                      2                       6.0   \n127553                     1                       6.0   \n85588                      1                       4.0   \n44808                      3                       2.0   \n\n        Have you ever had suicidal thoughts ?_Binary  \\\n127399                                             0   \n23578                                              1   \n127553                                             1   \n85588                                              0   \n44808                                              0   \n\n        Family History of Mental Illness_Binary  Overall_Satisfaction  \\\n127399                                        0                   1.0   \n23578                                         0                   2.0   \n127553                                        1                   2.5   \n85588                                         0                   2.5   \n44808                                         1                   2.0   \n\n        Overall_Pressure  \n127399               7.0  \n23578                8.0  \n127553               5.0  \n85588                7.0  \n44808                4.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Gender</th>\n      <th>City</th>\n      <th>Working Professional or Student</th>\n      <th>Profession</th>\n      <th>Sleep Duration</th>\n      <th>Dietary Habits</th>\n      <th>Degree</th>\n      <th>Have you ever had suicidal thoughts ?</th>\n      <th>Family History of Mental Illness</th>\n      <th>sleep_duration_cat</th>\n      <th>Degree Category</th>\n      <th>Profession_imputed</th>\n      <th>Age</th>\n      <th>Academic Pressure</th>\n      <th>Work Pressure</th>\n      <th>CGPA</th>\n      <th>Study Satisfaction</th>\n      <th>Job Satisfaction</th>\n      <th>Work/Study Hours</th>\n      <th>Financial Stress</th>\n      <th>Academic Pressure_imputed</th>\n      <th>Work Pressure_imputed</th>\n      <th>CGPA_imputed</th>\n      <th>Study Satisfaction_imputed</th>\n      <th>Job Satisfaction_imputed</th>\n      <th>sleep_duration_hours</th>\n      <th>Depression</th>\n      <th>Pressure_to_Satisfaction_Ratio</th>\n      <th>Pressure_Impact_on_CGPA</th>\n      <th>Work_Life_Balance</th>\n      <th>Stress_Level</th>\n      <th>Age_Group</th>\n      <th>Sleep_to_Work_Ratio</th>\n      <th>CGPA_Efficiency</th>\n      <th>Dietary_Health_Score</th>\n      <th>Mental_Health_Risk_Score</th>\n      <th>Have you ever had suicidal thoughts ?_Binary</th>\n      <th>Family History of Mental Illness_Binary</th>\n      <th>Overall_Satisfaction</th>\n      <th>Overall_Pressure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>127399</th>\n      <td>Gauri</td>\n      <td>Female</td>\n      <td>Varanasi</td>\n      <td>Student</td>\n      <td>Teacher</td>\n      <td>7-8 hours</td>\n      <td>Healthy</td>\n      <td>BCA</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Normal sleep duration</td>\n      <td>Bachelor</td>\n      <td>Student</td>\n      <td>28.0</td>\n      <td>4.000000</td>\n      <td>2.999668</td>\n      <td>6.530000</td>\n      <td>2.000000</td>\n      <td>2.973074</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>6.53</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>7.5</td>\n      <td>0</td>\n      <td>2.00</td>\n      <td>1.6325</td>\n      <td>7.500000e+08</td>\n      <td>7.0</td>\n      <td>Young Adults</td>\n      <td>7.500000e+08</td>\n      <td>6.530000e+08</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>23578</th>\n      <td>Shiv</td>\n      <td>Male</td>\n      <td>Agra</td>\n      <td>Working Professional</td>\n      <td>Research Analyst</td>\n      <td>5-6 hours</td>\n      <td>Moderate</td>\n      <td>M.Pharm</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Short sleep duration</td>\n      <td>Master and Higher</td>\n      <td>Research Analyst</td>\n      <td>47.0</td>\n      <td>3.145141</td>\n      <td>3.000000</td>\n      <td>7.662263</td>\n      <td>2.943501</td>\n      <td>4.000000</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>5.5</td>\n      <td>0</td>\n      <td>0.75</td>\n      <td>0.0000</td>\n      <td>1.357143e+00</td>\n      <td>8.0</td>\n      <td>Middle-aged</td>\n      <td>7.857143e-01</td>\n      <td>0.000000e+00</td>\n      <td>2</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>127553</th>\n      <td>Manvi</td>\n      <td>Female</td>\n      <td>Visakhapatnam</td>\n      <td>Student</td>\n      <td>Teacher</td>\n      <td>5-6 hours</td>\n      <td>Unhealthy</td>\n      <td>MBA</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Short sleep duration</td>\n      <td>Master and Higher</td>\n      <td>Student</td>\n      <td>25.0</td>\n      <td>1.000000</td>\n      <td>2.999668</td>\n      <td>7.090000</td>\n      <td>5.000000</td>\n      <td>2.973074</td>\n      <td>12.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.09</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>5.5</td>\n      <td>1</td>\n      <td>0.20</td>\n      <td>7.0900</td>\n      <td>4.583333e-01</td>\n      <td>5.0</td>\n      <td>Youth</td>\n      <td>4.583333e-01</td>\n      <td>5.908333e-01</td>\n      <td>1</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.5</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>85588</th>\n      <td>Pranav</td>\n      <td>Male</td>\n      <td>Varanasi</td>\n      <td>Working Professional</td>\n      <td>Pilot</td>\n      <td>Less than 5 hours</td>\n      <td>Unhealthy</td>\n      <td>BE</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Short sleep duration</td>\n      <td>Bachelor</td>\n      <td>Pilot</td>\n      <td>59.0</td>\n      <td>3.145141</td>\n      <td>3.000000</td>\n      <td>7.662263</td>\n      <td>2.943501</td>\n      <td>5.000000</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>2.5</td>\n      <td>0</td>\n      <td>0.60</td>\n      <td>0.0000</td>\n      <td>7.500000e+08</td>\n      <td>7.0</td>\n      <td>Middle-aged</td>\n      <td>2.500000e+08</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.5</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>44808</th>\n      <td>Aaradhya</td>\n      <td>Female</td>\n      <td>Indore</td>\n      <td>Working Professional</td>\n      <td>Pharmacist</td>\n      <td>7-8 hours</td>\n      <td>Healthy</td>\n      <td>B.Pharm</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Normal sleep duration</td>\n      <td>Bachelor</td>\n      <td>Pharmacist</td>\n      <td>45.0</td>\n      <td>3.145141</td>\n      <td>3.000000</td>\n      <td>7.662263</td>\n      <td>2.943501</td>\n      <td>4.000000</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>7.5</td>\n      <td>0</td>\n      <td>0.75</td>\n      <td>0.0000</td>\n      <td>1.437500e+00</td>\n      <td>4.0</td>\n      <td>Middle-aged</td>\n      <td>9.375000e-01</td>\n      <td>0.000000e+00</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"target=\"Depression\"\nX_train, y_train = df.drop(target, axis=1), df[target]\nX_test, y_test = test.drop(target, axis=1), test[target]","metadata":{"execution":{"iopub.status.busy":"2024-12-01T05:24:07.158890Z","iopub.execute_input":"2024-12-01T05:24:07.159338Z","iopub.status.idle":"2024-12-01T05:24:07.187977Z","shell.execute_reply.started":"2024-12-01T05:24:07.159285Z","shell.execute_reply":"2024-12-01T05:24:07.186774Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"col_mi=[\"Name\",\"City\",'Academic Pressure_imputed', 'Age','CGPA','CGPA_Efficiency',\n 'Degree', 'Dietary Habits','Dietary_Health_Score',\n 'Family History of Mental Illness','Financial Stress',\n 'Gender', 'Have you ever had suicidal thoughts ?_Binary', 'Job Satisfaction_imputed',\n 'Mental_Health_Risk_Score','Overall_Pressure','Overall_Satisfaction','Pressure_Impact_on_CGPA',\n 'Pressure_to_Satisfaction_Ratio', 'Profession_imputed', 'Sleep_to_Work_Ratio',\n 'Stress_Level', 'Study Satisfaction_imputed', 'Work Pressure_imputed',\n 'Work/Study Hours','Work_Life_Balance','Working Professional or Student','sleep_duration_cat']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:24:07.189281Z","iopub.execute_input":"2024-12-01T05:24:07.189836Z","iopub.status.idle":"2024-12-01T05:24:07.195384Z","shell.execute_reply.started":"2024-12-01T05:24:07.189786Z","shell.execute_reply":"2024-12-01T05:24:07.194289Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"X_train,X_test=X_train[col_mi],X_test[col_mi]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:15:11.720933Z","iopub.execute_input":"2024-12-01T09:15:11.721384Z","iopub.status.idle":"2024-12-01T09:15:11.747816Z","shell.execute_reply.started":"2024-12-01T09:15:11.721339Z","shell.execute_reply":"2024-12-01T09:15:11.746133Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"X_test_sumit=test_submit[col_mi]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:15:14.639450Z","iopub.execute_input":"2024-12-01T09:15:14.639927Z","iopub.status.idle":"2024-12-01T09:15:14.658636Z","shell.execute_reply.started":"2024-12-01T09:15:14.639886Z","shell.execute_reply":"2024-12-01T09:15:14.657136Z"}},"outputs":[],"execution_count":69},{"cell_type":"markdown","source":"# Trying different model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nimport numpy as np\n\nX_train_=pd.get_dummies(X_train)\nmodels = [\n    ('LR', LogisticRegression(max_iter=1000)),\n    ('KNN', KNeighborsClassifier()),\n    ('RFC', RandomForestClassifier(n_jobs=-1)),  # Use all CPU cores\n    ('NB', GaussianNB()),\n    ('SVM', LinearSVC()),\n]\n\nfor name, model in models:\n    scores = cross_val_score(model, X_train_, y_train, cv=3, scoring=\"accuracy\", n_jobs=-1)\n    print(scores)\n    print(f\"{name}: {np.mean(scores)} SD: {np.std(scores)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:24:14.775287Z","iopub.execute_input":"2024-12-01T05:24:14.775680Z","iopub.status.idle":"2024-12-01T05:28:56.692469Z","shell.execute_reply.started":"2024-12-01T05:24:14.775644Z","shell.execute_reply":"2024-12-01T05:28:56.691133Z"}},"outputs":[{"name":"stdout","text":"[0.82587953 0.83067697 0.82947761]\nLR: 0.828678038379531 SD: 0.002038520594453418\n[0.91857676 0.91966951 0.92004264]\nKNN: 0.9194296375266524 SD: 0.000622017450753901\n[0.93219616 0.93483475 0.93398188]\nRFC: 0.9336709310589907 SD: 0.0010994114025807444\n[0.8163113  0.81585821 0.81548507]\nNB: 0.8158848614072495 SD: 0.0003378314381988405\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[0.8646322  0.86711087 0.90764925]\nSVM: 0.8797974413646056 SD: 0.019720185095285173\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nimport numpy as np\n\n# Assuming X_train and y_train are already defined\n\n# Identify categorical and numerical features\ncat_features = X_train.select_dtypes(exclude=np.number).columns\nnum_features = X_train.select_dtypes(include=np.number).columns\n\n# Create a pipeline for preprocessing\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_features),  \n        (\"num\", \"passthrough\", num_features),    # Leave numerical features as is\n    ]\n)\n\n# Define the model\nmodel = RandomForestClassifier(random_state=42)\n\n# Create a pipeline\npipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", model)])\n\n# Perform 3-fold cross-validation\ncv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n\n# Evaluate the model\ncv_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n\nprint(\"Cross-Validation Scores:\", cv_scores)\nprint(\"Mean Accuracy:\", np.mean(cv_scores))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:32:39.011075Z","iopub.execute_input":"2024-12-01T05:32:39.011634Z","iopub.status.idle":"2024-12-01T05:32:56.213588Z","shell.execute_reply.started":"2024-12-01T05:32:39.011505Z","shell.execute_reply":"2024-12-01T05:32:56.212415Z"}},"outputs":[{"name":"stdout","text":"Cross-Validation Scores: [0.93598081 0.93523454 0.93579424]\nMean Accuracy: 0.9356698649609098\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# HyperParameter Tuning","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nfrom category_encoders import TargetEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\n\n# Identify categorical and numerical columns\ncategorical_columns = X_train.select_dtypes(include=['object']).columns\nnumerical_columns = X_train.select_dtypes(include=['number']).columns\n\n# Preprocessing pipelines\ndef get_preprocessor(encoder):\n    if encoder == \"OneHotEncoder\":\n        return ColumnTransformer(transformers=[\n            ('num', SimpleImputer(strategy='mean'), numerical_columns),\n            ('cat', Pipeline([\n                ('imputer', SimpleImputer(strategy='most_frequent')),\n                ('encoder', OneHotEncoder(handle_unknown='ignore'))\n            ]), categorical_columns)\n        ])\n    elif encoder == \"OrdinalEncoder\":\n        return ColumnTransformer(transformers=[\n            ('num', SimpleImputer(strategy='mean'), numerical_columns),\n            ('cat', Pipeline([\n                ('imputer', SimpleImputer(strategy='most_frequent')),\n                ('encoder', OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n            ]), categorical_columns)\n        ])\n    elif encoder == \"TargetEncoder\":\n        return Pipeline(steps=[\n            ('imputer', SimpleImputer(strategy='mean')),\n            ('encoder', TargetEncoder(cols=categorical_columns))\n        ])\n    else:\n        raise ValueError(\"Invalid encoder selected.\")\n\n# Define RandomForest model\nrf_model = RandomForestClassifier(random_state=42)\n\n# Hyperparameter grid\nparam_grid = {\n    'preprocessor': ['OneHotEncoder', 'OrdinalEncoder', 'TargetEncoder'],\n    'classifier__n_estimators': [50, 100, 200, 500],\n    'classifier__max_depth': [None, 10, 20, 30],\n    'classifier__min_samples_split': [2, 5, 10],\n    'classifier__min_samples_leaf': [1, 2, 4],\n    'classifier__max_features': ['auto', 'sqrt', 'log2']\n}\n\n# Pipeline with preprocessor and model\npipeline = Pipeline([\n    ('preprocessor', get_preprocessor(\"OneHotEncoder\")),  \n    ('classifier', rf_model)\n])\n\n# Prepare parameter grid for RandomizedSearchCV\nparam_dist = {\n    'preprocessor': [get_preprocessor(encoder) for encoder in ['OneHotEncoder', 'OrdinalEncoder', 'TargetEncoder']],\n    'classifier__n_estimators': [50, 100, 200, 500],\n    'classifier__max_depth': [None,5, 10, 20, 30],\n    'classifier__min_samples_split': [2, 5, 10],\n    'classifier__min_samples_leaf': [1, 2, 4],\n    'classifier__max_features': ['auto', 'sqrt', 'log2']\n}\n# RandomizedSearchCV\nrandom_search = RandomizedSearchCV(\n    pipeline,\n    param_distributions=param_dist,\n    n_iter=20,\n    cv=3,\n    scoring='accuracy',\n    verbose=2,\n    random_state=42\n)\n\n# Fit RandomizedSearchCV\nrandom_search.fit(X_train, y_train)\n\n# Best Parameters and Score\nprint(\"Best Parameters:\", random_search.best_params_)\nprint(\"Best Score:\", random_search.best_score_)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:35:53.976276Z","iopub.execute_input":"2024-12-01T05:35:53.976701Z","iopub.status.idle":"2024-12-01T05:52:50.126410Z","shell.execute_reply.started":"2024-12-01T05:35:53.976663Z","shell.execute_reply":"2024-12-01T05:52:50.124656Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 20 candidates, totalling 60 fits\n[CV] END classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  56.6s\n[CV] END classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  57.6s\n[CV] END classifier__max_depth=None, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  58.5s\n[CV] END classifier__max_depth=5, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=5, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=5, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.2s\n[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=50, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  10.6s\n[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=50, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  10.2s\n[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=50, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   9.9s\n[CV] END classifier__max_depth=5, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   2.7s\n[CV] END classifier__max_depth=5, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   2.7s\n[CV] END classifier__max_depth=5, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   2.7s\n[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  32.4s\n[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  31.6s\n[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  31.6s\n[CV] END classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   5.6s\n[CV] END classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   5.5s\n[CV] END classifier__max_depth=20, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   5.7s\n[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=100, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=200, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  17.2s\n[CV] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=200, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  17.3s\n[CV] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=200, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  17.2s\n[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  20.2s\n[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  20.5s\n[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  20.5s\n[CV] END classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=200, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  18.9s\n[CV] END classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=200, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  18.6s\n[CV] END classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=200, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  18.8s\n[CV] END classifier__max_depth=5, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=5, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=5, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=200, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   8.8s\n[CV] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   8.9s\n[CV] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   8.8s\n[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=None, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=None, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=None, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=5, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   1.7s\n[CV] END classifier__max_depth=5, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   1.6s\n[CV] END classifier__max_depth=5, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=50, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   1.6s\n[CV] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  11.0s\n[CV] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  11.0s\n[CV] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2, classifier__n_estimators=100, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  11.0s\n[CV] END classifier__max_depth=5, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=200, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=5, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=200, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=5, classifier__max_features=auto, classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=200, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time= 2.4min\n[CV] END classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time= 2.4min\n[CV] END classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=2, classifier__n_estimators=500, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time= 2.4min\n[CV] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=50, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=50, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=10, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=50, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=50, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   4.8s\n[CV] END classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=50, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   4.8s\n[CV] END classifier__max_depth=None, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2, classifier__n_estimators=50, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   4.8s\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n21 fits failed out of a total of 60.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n7 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 881, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 390, in fit\n    X = self._validate_input(X, in_fit=True)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 342, in _validate_input\n    raise new_ve from None\nValueError: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'Aarav'\n\n--------------------------------------------------------------------------------\n14 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 881, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 390, in fit\n    X = self._validate_input(X, in_fit=True)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 342, in _validate_input\n    raise new_ve from None\nValueError: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'Gauri'\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.93314677        nan 0.91657783 0.84055615 0.91428571 0.93657605\n        nan 0.93618515 0.8996624  0.9363806         nan 0.93614961\n        nan        nan 0.83597193 0.91522743        nan 0.9208511\n        nan 0.9358742 ]\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Best Parameters: {'preprocessor': ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]), 'classifier__n_estimators': 50, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 4, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 20}\nBest Score: 0.9365760483297797\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\ny_pred=random_search.predict(X_test)\nacc=accuracy_score(y_test,y_pred)\nprint(acc)\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:31:30.601261Z","iopub.execute_input":"2024-12-01T07:31:30.601698Z","iopub.status.idle":"2024-12-01T07:31:30.802166Z","shell.execute_reply.started":"2024-12-01T07:31:30.601660Z","shell.execute_reply":"2024-12-01T07:31:30.800816Z"}},"outputs":[{"name":"stdout","text":"0.9338308457711443\n              precision    recall  f1-score   support\n\n           0       0.97      0.95      0.96     23050\n           1       0.79      0.87      0.83      5090\n\n    accuracy                           0.93     28140\n   macro avg       0.88      0.91      0.89     28140\nweighted avg       0.94      0.93      0.94     28140\n\n[[21839  1211]\n [  651  4439]]\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"# Catboost","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer, make_column_selector\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import cross_val_score\nX_train_C=X_train.copy()\nX_test_C=X_test.copy()\nfor col in [col for col in X_train.select_dtypes(np.number).columns]:\n    X_train_C[col] = X_train[col].astype(\"float\")\n    X_test_C[col] = X_test[col].astype(\"float\")\n# Convert categorical columns back to 'string' if required by CatBoost\nfor col in X_train.select_dtypes(exclude=np.number).columns:\n    X_train_C[col] = X_train[col].astype(\"string\")\n    X_test_C[col] = X_test[col].astype(\"string\")","metadata":{"execution":{"iopub.status.busy":"2024-12-01T06:05:54.506715Z","iopub.execute_input":"2024-12-01T06:05:54.507940Z","iopub.status.idle":"2024-12-01T06:05:54.625111Z","shell.execute_reply.started":"2024-12-01T06:05:54.507870Z","shell.execute_reply":"2024-12-01T06:05:54.623758Z"},"trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":"string_columns = X_train_C.select_dtypes(\"string\").columns\n\n# Get column indices (positions)\ncol_indices = X_train_C.columns.get_indexer(string_columns)","metadata":{"execution":{"iopub.status.busy":"2024-12-01T06:05:58.109631Z","iopub.execute_input":"2024-12-01T06:05:58.110202Z","iopub.status.idle":"2024-12-01T06:05:58.149524Z","shell.execute_reply.started":"2024-12-01T06:05:58.110148Z","shell.execute_reply":"2024-12-01T06:05:58.147835Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"model = CatBoostClassifier(cat_features=col_indices,verbose=0)\nscores = cross_val_score(model, X_train_C, y_train, cv=3, scoring=\"accuracy\")\nprint(scores)\nprint(f\"catboost: {np.mean(scores)} SD: {np.std(scores)}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-01T06:05:59.859291Z","iopub.execute_input":"2024-12-01T06:05:59.859884Z","iopub.status.idle":"2024-12-01T06:09:42.125318Z","shell.execute_reply.started":"2024-12-01T06:05:59.859829Z","shell.execute_reply":"2024-12-01T06:09:42.123839Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[0.93829957 0.94043177 0.93907249]\ncatboost: 0.9392679459843639 SD: 0.0008813686442953937\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"# Hyper parameter tuning for catboost","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\n# Define the CatBoostClassifier\nmodel = CatBoostClassifier(verbose=0, random_seed=42,cat_features=col_indices,)\n\n# Define the hyperparameter grid\nparam_dist = {\n    \"iterations\": [100, 200, 300, 500, 1000],\n    \"learning_rate\": np.logspace(-3, 0, 10),\n    \"depth\": [4, 6, 8, 10],\n    \"l2_leaf_reg\": [1, 3, 5, 7, 9],\n    \"bagging_temperature\": [0, 0.5, 1, 1.5, 2],\n    \"border_count\": [32, 64, 128],\n    \"auto_class_weights\": [None, \"Balanced\", \"SqrtBalanced\"],\n}\n\n# Set up RandomizedSearchCV\nrandom_search = RandomizedSearchCV(\n    estimator=model,\n    param_distributions=param_dist,\n    n_iter=50,  # Number of random configurations to test\n    scoring=\"accuracy\",  # You can change this to other metrics like 'f1' or 'roc_auc'\n    cv=3,  # 3-fold cross-validation\n    verbose=1,\n    random_state=42,\n    n_jobs=-1,  # Use all processors\n)\n\n# Fit RandomizedSearchCV\nrandom_search.fit(X_train_C, y_train)\n\n# Print the best parameters and score\nprint(\"Best Parameters:\", random_search.best_params_)\nprint(\"Best Cross-Validation Score:\", random_search.best_score_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T06:10:17.477424Z","iopub.execute_input":"2024-12-01T06:10:17.477953Z","iopub.status.idle":"2024-12-01T07:10:17.499094Z","shell.execute_reply.started":"2024-12-01T06:10:17.477912Z","shell.execute_reply":"2024-12-01T07:10:17.496963Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 50 candidates, totalling 150 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n63 fits failed out of a total of 150.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n63 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 5245, in fit\n    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2395, in _fit\n    train_params = self._prepare_train_params(\n  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2321, in _prepare_train_params\n    _check_train_params(params)\n  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\n  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\n_catboost.CatBoostError: catboost/private/libs/options/json_helper.h:41: Can't parse parameter \"auto_class_weights\" with value: null\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.9195629         nan 0.93399964 0.93494136        nan        nan\n 0.91311301 0.93502132 0.92017591 0.92019367 0.90333156 0.91750178\n        nan        nan        nan        nan 0.92687456 0.9339108\n 0.92643923 0.92168621 0.91821251        nan 0.91149609 0.93516347\n 0.92919332 0.91766169 0.91163824        nan        nan 0.92221038\n 0.93194741        nan        nan 0.92783404        nan        nan\n        nan 0.93607854 0.93098792        nan 0.92553305        nan\n        nan 0.93180526 0.91494314        nan 0.91538735        nan\n 0.93158316        nan]\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Best Parameters: {'learning_rate': 0.1, 'l2_leaf_reg': 1, 'iterations': 300, 'depth': 8, 'border_count': 128, 'bagging_temperature': 1.5, 'auto_class_weights': 'SqrtBalanced'}\nBest Cross-Validation Score: 0.9360785358919688\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"best_params_={'learning_rate': 0.1, 'l2_leaf_reg': 1, 'iterations': 300, 'depth': 8, 'border_count': 128, 'bagging_temperature': 1.5, 'auto_class_weights': 'SqrtBalanced'}\nmodel_cat = CatBoostClassifier(verbose=0, random_seed=42,cat_features=col_indices,**best_params_)\nmodel_cat.fit(X_train,y_train,verbose=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:35:41.543082Z","iopub.execute_input":"2024-12-01T07:35:41.543575Z","iopub.status.idle":"2024-12-01T07:36:24.208345Z","shell.execute_reply.started":"2024-12-01T07:35:41.543536Z","shell.execute_reply":"2024-12-01T07:36:24.207166Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<catboost.core.CatBoostClassifier at 0x7f65aef62c80>"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\ny_pred=model_cat.predict(X_test)\nacc=accuracy_score(y_test,y_pred)\nprint(acc)\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:38:34.586892Z","iopub.execute_input":"2024-12-01T07:38:34.587498Z","iopub.status.idle":"2024-12-01T07:38:34.813253Z","shell.execute_reply.started":"2024-12-01T07:38:34.587458Z","shell.execute_reply":"2024-12-01T07:38:34.811785Z"}},"outputs":[{"name":"stdout","text":"0.9338308457711443\n              precision    recall  f1-score   support\n\n           0       0.97      0.95      0.96     23050\n           1       0.79      0.87      0.83      5090\n\n    accuracy                           0.93     28140\n   macro avg       0.88      0.91      0.89     28140\nweighted avg       0.94      0.93      0.94     28140\n\n[[21839  1211]\n [  651  4439]]\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# XGBoost HyperParameter tuning","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nfrom category_encoders import TargetEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom xgboost import XGBClassifier\n\n# Identify categorical and numerical columns\ncategorical_columns = X_train.select_dtypes(include=['object']).columns\nnumerical_columns = X_train.select_dtypes(include=['number']).columns\n\n# Preprocessing pipelines\ndef get_preprocessor(encoder):\n    if encoder == \"OneHotEncoder\":\n        return ColumnTransformer(transformers=[\n            ('num', SimpleImputer(strategy='mean'), numerical_columns),\n            ('cat', Pipeline([\n                ('imputer', SimpleImputer(strategy='most_frequent')),\n                ('encoder', OneHotEncoder(handle_unknown='ignore'))\n            ]), categorical_columns)\n        ])\n    elif encoder == \"OrdinalEncoder\":\n        return ColumnTransformer(transformers=[\n            ('num', SimpleImputer(strategy='mean'), numerical_columns),\n            ('cat', Pipeline([\n                ('imputer', SimpleImputer(strategy='most_frequent')),\n                ('encoder', OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n            ]), categorical_columns)\n        ])\n    elif encoder == \"TargetEncoder\":\n        return Pipeline(steps=[\n            ('imputer', SimpleImputer(strategy='mean')),\n            ('encoder', TargetEncoder(cols=categorical_columns))\n        ])\n    else:\n        raise ValueError(\"Invalid encoder selected.\")\n\n# Define XGBClassifier model\nxgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n\n# Hyperparameter grid\nparam_grid = {\n    'preprocessor': ['OneHotEncoder', 'OrdinalEncoder', 'TargetEncoder'],\n    'classifier__n_estimators': [50, 100, 200, 500],\n    'classifier__max_depth': [3, 5, 10, 20],\n    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n    'classifier__subsample': [0.6, 0.8, 1.0],\n    'classifier__colsample_bytree': [0.6, 0.8, 1.0],\n    'classifier__gamma': [0, 0.1, 0.5, 1],\n}\n\n# Pipeline with preprocessor and model\npipeline = Pipeline([\n    ('preprocessor', get_preprocessor(\"OneHotEncoder\")),\n    ('classifier', xgb_model)\n])\n\n# Prepare parameter grid for RandomizedSearchCV\nparam_dist = {\n    'preprocessor': [get_preprocessor(encoder) for encoder in ['OneHotEncoder', 'OrdinalEncoder', 'TargetEncoder']],\n    'classifier__n_estimators': [50, 100, 200, 500],\n    'classifier__max_depth': [3, 5, 10, 20],\n    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n    'classifier__subsample': [0.6, 0.8, 1.0],\n    'classifier__colsample_bytree': [0.6, 0.8, 1.0],\n    'classifier__gamma': [0, 0.1, 0.5, 1],\n}\n\n# RandomizedSearchCV\nrandom_search_XGB = RandomizedSearchCV(\n    pipeline,\n    param_distributions=param_dist,\n    n_iter=20,\n    cv=3,\n    scoring='accuracy',\n    verbose=0,\n    random_state=42,\n    n_jobs=-1\n)\n\n# Fit RandomizedSearchCV\nrandom_search_XGB.fit(X_train, y_train)\n\n# Best Parameters and Score\nprint(\"Best Parameters:\", random_search_XGB.best_params_)\nprint(\"Best Score:\", random_search_XGB.best_score_)\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\ny_pred=random_search_XGB.predict(X_test)\nacc=accuracy_score(y_test,y_pred)\nprint(acc)\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T08:13:20.621527Z","iopub.execute_input":"2024-12-01T08:13:20.622034Z","iopub.status.idle":"2024-12-01T08:16:53.638730Z","shell.execute_reply.started":"2024-12-01T08:13:20.621992Z","shell.execute_reply":"2024-12-01T08:16:53.637250Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n12 fits failed out of a total of 60.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 881, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 390, in fit\n    X = self._validate_input(X, in_fit=True)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 342, in _validate_input\n    raise new_ve from None\nValueError: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'Aarav'\n\n--------------------------------------------------------------------------------\n8 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 881, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 390, in fit\n    X = self._validate_input(X, in_fit=True)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 342, in _validate_input\n    raise new_ve from None\nValueError: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'Gauri'\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.85020434 0.81807925 0.93949005        nan\n 0.93481699 0.93517235 0.93923241 0.93321784 0.93797974 0.93614072\n 0.93880597 0.93546553 0.9366027  0.84753021 0.93404407        nan\n 0.93842395 0.92902452]\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Best Parameters: {'preprocessor': ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]), 'classifier__subsample': 0.6, 'classifier__n_estimators': 500, 'classifier__max_depth': 3, 'classifier__learning_rate': 0.1, 'classifier__gamma': 0.5, 'classifier__colsample_bytree': 0.8}\nBest Score: 0.9394900497512437\n0.9378109452736318\n              precision    recall  f1-score   support\n\n           0       0.96      0.97      0.96     23050\n           1       0.84      0.81      0.83      5090\n\n    accuracy                           0.94     28140\n   macro avg       0.90      0.89      0.89     28140\nweighted avg       0.94      0.94      0.94     28140\n\n[[22259   791]\n [  959  4131]]\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"# LightGBM","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nfrom category_encoders import TargetEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom lightgbm import LGBMClassifier\n\n# Identify categorical and numerical columns\ncategorical_columns = X_train.select_dtypes(include=['object']).columns\nnumerical_columns = X_train.select_dtypes(include=['number']).columns\n\n# Preprocessing pipelines\ndef get_preprocessor(encoder):\n    if encoder == \"OneHotEncoder\":\n        return ColumnTransformer(transformers=[\n            ('num', SimpleImputer(strategy='mean'), numerical_columns),\n            ('cat', Pipeline([\n                ('imputer', SimpleImputer(strategy='most_frequent')),\n                ('encoder', OneHotEncoder(handle_unknown='ignore'))\n            ]), categorical_columns)\n        ])\n    elif encoder == \"OrdinalEncoder\":\n        return ColumnTransformer(transformers=[\n            ('num', SimpleImputer(strategy='mean'), numerical_columns),\n            ('cat', Pipeline([\n                ('imputer', SimpleImputer(strategy='most_frequent')),\n                ('encoder', OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n            ]), categorical_columns)\n        ])\n    elif encoder == \"TargetEncoder\":\n        return Pipeline(steps=[\n            ('imputer', SimpleImputer(strategy='mean')),\n            ('encoder', TargetEncoder(cols=categorical_columns))\n        ])\n    else:\n        raise ValueError(\"Invalid encoder selected.\")\n\n# Define LGBMClassifier model\nlgbm_model = LGBMClassifier(random_state=42)\n\n# Hyperparameter grid\nparam_grid = {\n    'preprocessor': ['OneHotEncoder', 'OrdinalEncoder', 'TargetEncoder'],\n    'classifier__n_estimators': [50, 100, 200, 500],\n    'classifier__max_depth': [-1, 3, 5, 10, 20],\n    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n    'classifier__subsample': [0.6, 0.8, 1.0],\n    'classifier__colsample_bytree': [0.6, 0.8, 1.0],\n    'classifier__min_child_samples': [10, 20, 30, 40],\n    'classifier__reg_alpha': [0, 0.1, 0.5, 1],\n    'classifier__reg_lambda': [0, 0.1, 0.5, 1],\n}\n\n# Pipeline with preprocessor and model\npipeline = Pipeline([\n    ('preprocessor', get_preprocessor(\"OneHotEncoder\")),\n    ('classifier', lgbm_model)\n])\n\n# Prepare parameter grid for RandomizedSearchCV\nparam_dist = {\n    'preprocessor': [get_preprocessor(encoder) for encoder in ['OneHotEncoder', 'OrdinalEncoder', 'TargetEncoder']],\n    'classifier__n_estimators': [50, 100, 200, 500],\n    'classifier__max_depth': [-1, 3, 5, 10, 20],\n    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n    'classifier__subsample': [0.6, 0.8, 1.0],\n    'classifier__colsample_bytree': [0.6, 0.8, 1.0],\n    'classifier__min_child_samples': [10, 20, 30, 40],\n    'classifier__reg_alpha': [0, 0.1, 0.5, 1],\n    'classifier__reg_lambda': [0, 0.1, 0.5, 1],\n}\n\n# RandomizedSearchCV\nrandom_search_lgbm = RandomizedSearchCV(\n    pipeline,\n    param_distributions=param_dist,\n    n_iter=20,\n    cv=3,\n    scoring='accuracy',\n    verbose=2,\n    random_state=42,\n    n_jobs=-1\n)\n\n# Fit RandomizedSearchCV\nrandom_search_lgbm.fit(X_train, y_train)\n\n# Best Parameters and Score\nprint(\"Best Parameters:\", random_search_lgbm.best_params_)\nprint(\"Best Score:\", random_search_lgbm.best_score_)\ny_pred=random_search_lgbm.predict(X_test)\nacc=accuracy_score(y_test,y_pred)\nprint(acc)\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:54:57.499625Z","iopub.execute_input":"2024-12-01T07:54:57.500228Z","iopub.status.idle":"2024-12-01T07:56:48.266208Z","shell.execute_reply.started":"2024-12-01T07:54:57.500187Z","shell.execute_reply":"2024-12-01T07:56:48.264561Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 20 candidates, totalling 60 fits\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.1, classifier__max_depth=5, classifier__min_child_samples=40, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.5, classifier__subsample=1.0, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.2s\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.05, classifier__max_depth=-1, classifier__min_child_samples=10, classifier__n_estimators=50, classifier__reg_alpha=0, classifier__reg_lambda=0.1, classifier__subsample=0.8, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.2s\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.05, classifier__max_depth=-1, classifier__min_child_samples=10, classifier__n_estimators=50, classifier__reg_alpha=0, classifier__reg_lambda=0.1, classifier__subsample=0.8, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.2s\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.05, classifier__max_depth=-1, classifier__min_child_samples=10, classifier__n_estimators=50, classifier__reg_alpha=0, classifier__reg_lambda=0.1, classifier__subsample=0.8, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.1, classifier__max_depth=5, classifier__min_child_samples=10, classifier__n_estimators=50, classifier__reg_alpha=0.1, classifier__reg_lambda=1, classifier__subsample=1.0, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.2s\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.1, classifier__max_depth=5, classifier__min_child_samples=10, classifier__n_estimators=50, classifier__reg_alpha=0.1, classifier__reg_lambda=1, classifier__subsample=1.0, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.1, classifier__max_depth=5, classifier__min_child_samples=10, classifier__n_estimators=50, classifier__reg_alpha=0.1, classifier__reg_lambda=1, classifier__subsample=1.0, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.1s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13652, number of negative: 61388\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044318 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1770\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 334\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181930 -> initscore=-1.503328\n[LightGBM] [Info] Start training from score -1.503328\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.1, classifier__max_depth=5, classifier__min_child_samples=40, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.5, classifier__subsample=1.0, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.2s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015649 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1472\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.2, classifier__max_depth=5, classifier__min_child_samples=20, classifier__n_estimators=50, classifier__reg_alpha=0, classifier__reg_lambda=1, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   4.2s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056943 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1778\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 335\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.1, classifier__max_depth=5, classifier__min_child_samples=40, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.5, classifier__subsample=1.0, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.2s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043696 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1475\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.2, classifier__max_depth=5, classifier__min_child_samples=20, classifier__n_estimators=50, classifier__reg_alpha=0, classifier__reg_lambda=1, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   4.3s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047137 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1777\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 336\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13652, number of negative: 61388\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041548 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1473\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181930 -> initscore=-1.503328\n[LightGBM] [Info] Start training from score -1.503328\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.2, classifier__max_depth=5, classifier__min_child_samples=20, classifier__n_estimators=50, classifier__reg_alpha=0, classifier__reg_lambda=1, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   4.3s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13652, number of negative: 61388\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035721 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1473\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181930 -> initscore=-1.503328\n[LightGBM] [Info] Start training from score -1.503328\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.01, classifier__max_depth=10, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=0, classifier__reg_lambda=0.5, classifier__subsample=0.8, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   9.1s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13652, number of negative: 61388\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038942 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1778\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 338\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181930 -> initscore=-1.503328\n[LightGBM] [Info] Start training from score -1.503328\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.2, classifier__max_depth=20, classifier__min_child_samples=30, classifier__n_estimators=100, classifier__reg_alpha=0.5, classifier__reg_lambda=1, classifier__subsample=1.0, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   9.3s\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=1, classifier__reg_lambda=0, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   9.5s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035862 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1472\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.01, classifier__max_depth=10, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=0, classifier__reg_lambda=0.5, classifier__subsample=0.8, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   9.2s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13652, number of negative: 61388\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038593 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1770\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 334\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181930 -> initscore=-1.503328\n[LightGBM] [Info] Start training from score -1.503328\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=1, classifier__reg_lambda=0, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   9.5s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057014 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1779\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 337\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.2, classifier__max_depth=20, classifier__min_child_samples=30, classifier__n_estimators=100, classifier__reg_alpha=0.5, classifier__reg_lambda=1, classifier__subsample=1.0, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   9.4s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038767 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1778\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 335\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047564 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1777\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 336\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=1, classifier__reg_lambda=0, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   6.6s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036074 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1475\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.01, classifier__max_depth=10, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=0, classifier__reg_lambda=0.5, classifier__subsample=0.8, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   9.0s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038812 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1786\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 339\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.2, classifier__max_depth=20, classifier__min_child_samples=30, classifier__n_estimators=100, classifier__reg_alpha=0.5, classifier__reg_lambda=1, classifier__subsample=1.0, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   9.3s\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_samples=40, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.1, classifier__subsample=0.6, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.4s\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_samples=40, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.1, classifier__subsample=0.6, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.4s\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_samples=40, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.1, classifier__subsample=0.6, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.4s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.2, classifier__max_depth=5, classifier__min_child_samples=40, classifier__n_estimators=500, classifier__reg_alpha=0.5, classifier__reg_lambda=0.5, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  25.2s\n[LightGBM] [Info] Number of positive: 13652, number of negative: 61388\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047346 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1770\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 334\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181930 -> initscore=-1.503328\n[LightGBM] [Info] Start training from score -1.503328\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 13652, number of negative: 61388\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057516 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1770\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 334\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181930 -> initscore=-1.503328\n[LightGBM] [Info] Start training from score -1.503328\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.1, classifier__max_depth=20, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=0.1, classifier__reg_lambda=0, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  10.0s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056880 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1777\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 336\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.1, classifier__max_depth=20, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=0.1, classifier__reg_lambda=0, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  10.2s\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038492 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1778\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 335\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.2, classifier__max_depth=5, classifier__min_child_samples=40, classifier__n_estimators=500, classifier__reg_alpha=0.5, classifier__reg_lambda=0.5, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  25.7s\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038254 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1777\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 336\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[CV] END classifier__colsample_bytree=0.6, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_samples=40, classifier__n_estimators=500, classifier__reg_alpha=0.1, classifier__reg_lambda=0, classifier__subsample=0.8, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  21.5s\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.2, classifier__max_depth=5, classifier__min_child_samples=40, classifier__n_estimators=500, classifier__reg_alpha=0.5, classifier__reg_lambda=0.5, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  25.3s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057088 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1778\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 335\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.1, classifier__max_depth=20, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=0.1, classifier__reg_lambda=0, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  10.1s\n[CV] END classifier__colsample_bytree=0.6, classifier__learning_rate=0.2, classifier__max_depth=5, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=0.1, classifier__reg_lambda=0.1, classifier__subsample=0.8, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.4s\n[CV] END classifier__colsample_bytree=0.6, classifier__learning_rate=0.2, classifier__max_depth=5, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=0.1, classifier__reg_lambda=0.1, classifier__subsample=0.8, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.4s\n[CV] END classifier__colsample_bytree=0.6, classifier__learning_rate=0.2, classifier__max_depth=5, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=0.1, classifier__reg_lambda=0.1, classifier__subsample=0.8, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.5s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13652, number of negative: 61388\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047619 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1782\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 340\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181930 -> initscore=-1.503328\n[LightGBM] [Info] Start training from score -1.503328\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[CV] END classifier__colsample_bytree=0.6, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_samples=40, classifier__n_estimators=500, classifier__reg_alpha=0.1, classifier__reg_lambda=0, classifier__subsample=0.8, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  21.0s\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_samples=10, classifier__n_estimators=200, classifier__reg_alpha=0, classifier__reg_lambda=0.5, classifier__subsample=0.6, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.3s\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_samples=10, classifier__n_estimators=200, classifier__reg_alpha=0, classifier__reg_lambda=0.5, classifier__subsample=0.6, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.4s\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_samples=10, classifier__n_estimators=200, classifier__reg_alpha=0, classifier__reg_lambda=0.5, classifier__subsample=0.6, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.4s\n[LightGBM] [Info] Number of positive: 13652, number of negative: 61388\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095319 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1473\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181930 -> initscore=-1.503328\n[LightGBM] [Info] Start training from score -1.503328\n[CV] END classifier__colsample_bytree=0.6, classifier__learning_rate=0.01, classifier__max_depth=-1, classifier__min_child_samples=20, classifier__n_estimators=100, classifier__reg_alpha=0.1, classifier__reg_lambda=0.1, classifier__subsample=0.8, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   9.1s\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091944 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1472\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[CV] END classifier__colsample_bytree=0.6, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_samples=40, classifier__n_estimators=500, classifier__reg_alpha=0.1, classifier__reg_lambda=0, classifier__subsample=0.8, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  21.2s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056485 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1787\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 341\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.05, classifier__max_depth=20, classifier__min_child_samples=10, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.1, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  17.0s\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.05, classifier__max_depth=-1, classifier__min_child_samples=40, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.1, classifier__subsample=0.6, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.4s\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_samples=10, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.1, classifier__subsample=1.0, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.4s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095272 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1475\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.05, classifier__max_depth=20, classifier__min_child_samples=10, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.1, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  17.0s\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035737 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1475\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[CV] END classifier__colsample_bytree=0.6, classifier__learning_rate=0.01, classifier__max_depth=-1, classifier__min_child_samples=20, classifier__n_estimators=100, classifier__reg_alpha=0.1, classifier__reg_lambda=0.1, classifier__subsample=0.8, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   9.0s\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.05, classifier__max_depth=-1, classifier__min_child_samples=40, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.1, classifier__subsample=0.6, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.4s\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.05, classifier__max_depth=-1, classifier__min_child_samples=40, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.1, classifier__subsample=0.6, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.4s\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_samples=10, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.1, classifier__subsample=1.0, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.5s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026072 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1472\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047542 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1790\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 341\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.05, classifier__max_depth=20, classifier__min_child_samples=10, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.1, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=  16.9s\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_samples=10, classifier__n_estimators=200, classifier__reg_alpha=1, classifier__reg_lambda=0.1, classifier__subsample=1.0, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.4s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13652, number of negative: 61388\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105350 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1473\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181930 -> initscore=-1.503328\n[LightGBM] [Info] Start training from score -1.503328\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=0.6, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_samples=20, classifier__n_estimators=50, classifier__reg_alpha=1, classifier__reg_lambda=0.5, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   5.9s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035644 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1787\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 341\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n27 fits failed out of a total of 60.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n9 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 881, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 390, in fit\n    X = self._validate_input(X, in_fit=True)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 342, in _validate_input\n    raise new_ve from None\nValueError: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'Aarav'\n\n--------------------------------------------------------------------------------\n18 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/opt/conda/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/base.py\", line 881, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 390, in fit\n    X = self._validate_input(X, in_fit=True)\n  File \"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py\", line 342, in _validate_input\n    raise new_ve from None\nValueError: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'Gauri'\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.93854833        nan        nan 0.93842395 0.92473348\n 0.93802416 0.93697584        nan 0.93877043 0.93949005        nan\n 0.93876155        nan 0.91940299        nan        nan 0.81807925\n        nan 0.93879709]\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 20477, number of negative: 92083\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010185 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1792\n[LightGBM] [Info] Number of data points in the train set: 112560, number of used features: 340\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181921 -> initscore=-1.503388\n[LightGBM] [Info] Start training from score -1.503388\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nBest Parameters: {'preprocessor': ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]), 'classifier__subsample': 0.8, 'classifier__reg_lambda': 0, 'classifier__reg_alpha': 0.1, 'classifier__n_estimators': 500, 'classifier__min_child_samples': 40, 'classifier__max_depth': 3, 'classifier__learning_rate': 0.05, 'classifier__colsample_bytree': 0.6}\nBest Score: 0.9394900497512438\n0.9382018479033405\n              precision    recall  f1-score   support\n\n           0       0.96      0.97      0.96     23050\n           1       0.84      0.81      0.83      5090\n\n    accuracy                           0.94     28140\n   macro avg       0.90      0.89      0.89     28140\nweighted avg       0.94      0.94      0.94     28140\n\n[[22276   774]\n [  965  4125]]\n[CV] END classifier__colsample_bytree=0.6, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_samples=20, classifier__n_estimators=50, classifier__reg_alpha=1, classifier__reg_lambda=0.5, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   5.9s\n[CV] END classifier__colsample_bytree=0.6, classifier__learning_rate=0.01, classifier__max_depth=-1, classifier__min_child_samples=20, classifier__n_estimators=100, classifier__reg_alpha=0.1, classifier__reg_lambda=0.1, classifier__subsample=0.8, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   8.9s\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.01, classifier__max_depth=20, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=0.5, classifier__reg_lambda=1, classifier__subsample=1.0, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.3s\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.01, classifier__max_depth=20, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=0.5, classifier__reg_lambda=1, classifier__subsample=1.0, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.4s\n[CV] END classifier__colsample_bytree=1.0, classifier__learning_rate=0.01, classifier__max_depth=20, classifier__min_child_samples=40, classifier__n_estimators=100, classifier__reg_alpha=0.5, classifier__reg_lambda=1, classifier__subsample=1.0, preprocessor=Pipeline(steps=[('imputer', SimpleImputer()),\n                ('encoder',\n                 TargetEncoder(cols=Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object')))]); total time=   0.4s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13652, number of negative: 61388\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029630 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1782\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 340\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181930 -> initscore=-1.503328\n[LightGBM] [Info] Start training from score -1.503328\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.2, classifier__max_depth=5, classifier__min_child_samples=10, classifier__n_estimators=50, classifier__reg_alpha=0.1, classifier__reg_lambda=0.5, classifier__subsample=0.8, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   4.9s\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.2, classifier__max_depth=5, classifier__min_child_samples=10, classifier__n_estimators=50, classifier__reg_alpha=0.1, classifier__reg_lambda=0.5, classifier__subsample=0.8, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   4.6s\n[CV] END classifier__colsample_bytree=0.6, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_samples=20, classifier__n_estimators=50, classifier__reg_alpha=1, classifier__reg_lambda=0.5, classifier__subsample=0.6, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n                                                                 unknown_value=-1))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   5.9s\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[LightGBM] [Info] Number of positive: 13651, number of negative: 61389\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035720 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1790\n[LightGBM] [Info] Number of data points in the train set: 75040, number of used features: 341\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181916 -> initscore=-1.503418\n[LightGBM] [Info] Start training from score -1.503418\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n[CV] END classifier__colsample_bytree=0.8, classifier__learning_rate=0.2, classifier__max_depth=5, classifier__min_child_samples=10, classifier__n_estimators=50, classifier__reg_alpha=0.1, classifier__reg_lambda=0.5, classifier__subsample=0.8, preprocessor=ColumnTransformer(transformers=[('num', SimpleImputer(),\n                                 Index(['Academic Pressure_imputed', 'Age', 'CGPA', 'CGPA_Efficiency',\n       'Dietary_Health_Score', 'Financial Stress',\n       'Have you ever had suicidal thoughts ?_Binary',\n       'Job Satisfaction_imputed', 'Mental_Health_Risk_Score',\n       'Overall_Pressure', 'Overall_Satisfaction', 'Pressure_Impact_on_CGPA',\n       'Pressure_to_Satisfaction_R...\n       'Work/Study Hours', 'Work_Life_Balance'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('encoder',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index(['Name', 'City', 'Degree', 'Dietary Habits',\n       'Family History of Mental Illness', 'Gender', 'Profession_imputed',\n       'Working Professional or Student', 'sleep_duration_cat'],\n      dtype='object'))]); total time=   4.2s\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"# Ensemble all","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Assuming X_train, X_test, y_train, y_test are predefined\n\n# 1. Define numeric and categorical features\nnumeric_features = X_train.select_dtypes(np.number).columns\ncategorical_features = X_train.select_dtypes(exclude=np.number).columns\n# 2. Preprocessing pipelines\nnumeric_transformer = SimpleImputer(strategy='mean')\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)\n    ]\n)\n\n# 3. Define base models\nrf_model = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', RandomForestClassifier(\n        n_estimators=50, min_samples_split=5, min_samples_leaf=4,\n        max_features='sqrt', max_depth=20, random_state=42\n    ))\n])\n\ncatboost_model = CatBoostClassifier(cat_features=col_indices,\n    learning_rate=0.1, l2_leaf_reg=1, iterations=300, depth=8,\n    border_count=128, bagging_temperature=1.5, auto_class_weights='SqrtBalanced',\n    verbose=0\n)\n\nxgboost_model = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', XGBClassifier(\n        subsample=0.6, n_estimators=500, max_depth=3, learning_rate=0.1,\n        gamma=0.5, colsample_bytree=0.8, random_state=42, verbosity=0\n    ))\n])\n\nlightgbm_model = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', LGBMClassifier(\n        subsample=0.8, reg_lambda=0, reg_alpha=0.1, n_estimators=500,\n        min_child_samples=40, max_depth=3, learning_rate=0.05,\n        colsample_bytree=0.6, random_state=42\n    ))\n])\n\n# 4. Define stacking classifier\nstacking_model = StackingClassifier(\n    estimators=[\n        ('RandomForest', rf_model),\n        ('CatBoost', catboost_model),\n        ('LightGBM', lightgbm_model)\n    ],\n    final_estimator=XGBClassifier(\n        subsample=0.6, n_estimators=500, max_depth=3, learning_rate=0.1,\n        gamma=0.5, colsample_bytree=0.8, random_state=42, verbosity=0\n    ),\n    n_jobs=-1\n)\n\n# 5. Train and evaluate the stacking model\nstacking_model.fit(X_train, y_train)\ny_pred = stacking_model.predict(X_test)\n\n# 6. Output accuracy score\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Stacking Classifier Accuracy: {accuracy:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T08:37:19.827567Z","iopub.execute_input":"2024-12-01T08:37:19.828093Z","iopub.status.idle":"2024-12-01T08:42:24.044463Z","shell.execute_reply.started":"2024-12-01T08:37:19.828054Z","shell.execute_reply":"2024-12-01T08:42:24.043100Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 20477, number of negative: 92083\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031159 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1493\n[LightGBM] [Info] Number of data points in the train set: 112560, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181921 -> initscore=-1.503388\n[LightGBM] [Info] Start training from score -1.503388\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 16382, number of negative: 73666\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024879 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1479\n[LightGBM] [Info] Number of data points in the train set: 90048, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181925 -> initscore=-1.503358\n[LightGBM] [Info] Start training from score -1.503358\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 16382, number of negative: 73666\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024824 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1485\n[LightGBM] [Info] Number of data points in the train set: 90048, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181925 -> initscore=-1.503358\n[LightGBM] [Info] Start training from score -1.503358\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 16382, number of negative: 73666\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024982 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1483\n[LightGBM] [Info] Number of data points in the train set: 90048, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181925 -> initscore=-1.503358\n[LightGBM] [Info] Start training from score -1.503358\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 16381, number of negative: 73667\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025209 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1487\n[LightGBM] [Info] Number of data points in the train set: 90048, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181914 -> initscore=-1.503433\n[LightGBM] [Info] Start training from score -1.503433\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 16381, number of negative: 73667\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024351 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1477\n[LightGBM] [Info] Number of data points in the train set: 90048, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181914 -> initscore=-1.503433\n[LightGBM] [Info] Start training from score -1.503433\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nStacking Classifier Accuracy: 0.938\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score\n\n# 1. Define base models with their best parameters\nrf_model = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', RandomForestClassifier(\n        n_estimators=50, min_samples_split=5, min_samples_leaf=4,\n        max_features='sqrt', max_depth=20, random_state=42\n    ))\n])\n\ncatboost_model = CatBoostClassifier(cat_features=col_indices,\n    learning_rate=0.1, l2_leaf_reg=1, iterations=300, depth=8,\n    border_count=128, bagging_temperature=1.5, auto_class_weights='SqrtBalanced',\n    verbose=0\n)\n\nxgboost_model = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', XGBClassifier(\n        subsample=0.6, n_estimators=500, max_depth=3, learning_rate=0.1,\n        gamma=0.5, colsample_bytree=0.8, random_state=42, verbosity=0\n    ))\n])\n\nlightgbm_model = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', LGBMClassifier(\n        subsample=0.8, reg_lambda=0, reg_alpha=0.1, n_estimators=500,\n        min_child_samples=40, max_depth=3, learning_rate=0.05,\n        colsample_bytree=0.6, random_state=42\n    ))\n])\n\n# 2. Define the voting classifier\nvoting_model = VotingClassifier(\n    estimators=[\n        ('RandomForest', rf_model),\n        ('CatBoost', catboost_model),\n        ('LightGBM', lightgbm_model),\n        ('XGBoost', xgboost_model)\n    ],\n    voting='soft',  # Use soft voting for probabilistic predictions\n    n_jobs=-1\n)\n\n# 3. Train the voting classifier\nvoting_model.fit(X_train, y_train)\n\n# 4. Make predictions and evaluate\ny_pred = voting_model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\"Voting Classifier Accuracy: {accuracy:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T08:54:45.024138Z","iopub.execute_input":"2024-12-01T08:54:45.024649Z","iopub.status.idle":"2024-12-01T08:55:50.676079Z","shell.execute_reply.started":"2024-12-01T08:54:45.024518Z","shell.execute_reply":"2024-12-01T08:55:50.674711Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 20477, number of negative: 92083\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030664 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1493\n[LightGBM] [Info] Number of data points in the train set: 112560, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181921 -> initscore=-1.503388\n[LightGBM] [Info] Start training from score -1.503388\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nVoting Classifier Accuracy: 0.938\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"# Submit ","metadata":{}},{"cell_type":"code","source":"X_test_sumit.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:17:50.542196Z","iopub.execute_input":"2024-12-01T09:17:50.542680Z","iopub.status.idle":"2024-12-01T09:17:50.551116Z","shell.execute_reply.started":"2024-12-01T09:17:50.542599Z","shell.execute_reply":"2024-12-01T09:17:50.549888Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"(93800, 28)"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"y_pred_submit=voting_model.predict(X_test_sumit)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:22:50.513383Z","iopub.execute_input":"2024-12-01T09:22:50.513915Z","iopub.status.idle":"2024-12-01T09:22:55.375711Z","shell.execute_reply.started":"2024-12-01T09:22:50.513874Z","shell.execute_reply":"2024-12-01T09:22:55.374476Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"submission_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:17:07.438083Z","iopub.execute_input":"2024-12-01T09:17:07.438513Z","iopub.status.idle":"2024-12-01T09:17:07.446389Z","shell.execute_reply.started":"2024-12-01T09:17:07.438475Z","shell.execute_reply":"2024-12-01T09:17:07.445310Z"}},"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"(93800, 2)"},"metadata":{}}],"execution_count":74},{"cell_type":"code","source":"len(y_pred_submit)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:23:01.998087Z","iopub.execute_input":"2024-12-01T09:23:01.998484Z","iopub.status.idle":"2024-12-01T09:23:02.006690Z","shell.execute_reply.started":"2024-12-01T09:23:01.998454Z","shell.execute_reply":"2024-12-01T09:23:02.005439Z"}},"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"93800"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"submission_df[\"Depression\"]=y_pred_submit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:23:05.793366Z","iopub.execute_input":"2024-12-01T09:23:05.793785Z","iopub.status.idle":"2024-12-01T09:23:05.799793Z","shell.execute_reply.started":"2024-12-01T09:23:05.793717Z","shell.execute_reply":"2024-12-01T09:23:05.798446Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"submission_df.to_csv(\"submission6.csv\",index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:23:11.201085Z","iopub.execute_input":"2024-12-01T09:23:11.203875Z","iopub.status.idle":"2024-12-01T09:23:11.344105Z","shell.execute_reply.started":"2024-12-01T09:23:11.203809Z","shell.execute_reply":"2024-12-01T09:23:11.342967Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}